{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **What is a User-Agent?**\n",
    "\n",
    "The User-Agent (UA) is a string sent by a client (like a web browser or a bot) to identify itself to the server. It tells the server about the client’s operating system, browser, and device. For example, when you access a website via a browser like Chrome or Firefox, the browser sends a User-Agent string with each request to the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import httpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request {'Date': 'Thu, 10 Apr 2025 01:25:09 GMT', 'Content-Type': 'application/json', 'Content-Length': '305', 'Connection': 'keep-alive', 'Server': 'gunicorn/19.9.0', 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Credentials': 'true'}\n",
      "httpx Headers({'date': 'Thu, 10 Apr 2025 01:25:10 GMT', 'content-type': 'application/json', 'content-length': '302', 'connection': 'keep-alive', 'server': 'gunicorn/19.9.0', 'access-control-allow-origin': '*', 'access-control-allow-credentials': 'true'})\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Understanding Request Headers\n",
    "\"\"\"\n",
    "# TODO: Send request to https://httpbin.org/get using requests and httpx\n",
    "# TODO: Get the request headers from both responses\n",
    "# TODO: Compare the request headers and understand the difference\n",
    "\n",
    "req = requests.get('https://httpbin.org/get')\n",
    "r = httpx.get('https://httpbin.org/get')\n",
    "\n",
    "print(\"request\", req.headers)\n",
    "print(\"httpx\", r.headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36', 'Accept-Encoding': 'gzip, deflate, br', 'Accept': '*/*', 'Connection': 'keep-alive'}\n",
      "Original Headers:\n",
      "{'Date': 'Thu, 10 Apr 2025 01:25:21 GMT', 'Content-Type': 'application/json', 'Content-Length': '402', 'Connection': 'keep-alive', 'Server': 'gunicorn/19.9.0', 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Credentials': 'true'}\n",
      "\n",
      "Modified Headers:\n",
      "{'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36', 'Accept-Encoding': 'gzip, deflate, br', 'Accept': '*/*', 'Connection': 'keep-alive'}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Modify request headers\n",
    "\"\"\"\n",
    "# TODO: Send request to https://httpbin.org/get using requests\n",
    "# TODO: Get the request headers from the response\n",
    "\n",
    "r = requests.get('https://httpbin.org/get')\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Accept': '*/*',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Connection': 'keep-alive'\n",
    "}\n",
    "\n",
    "# TODO: Send new request using modified headers by passing headers params in get method\n",
    "# TODO: Get the request headers from the response\n",
    "# TODO: Compare the request headers and understand the difference\n",
    "# TODO: Experiment with different headers and share your thoughts\n",
    "\n",
    "# Send the request with modified headers\n",
    "r = requests.get('https://httpbin.org/get', headers=headers)\n",
    "\n",
    "# Get the request headers from the response\n",
    "print(r.request.headers)\n",
    "\n",
    "# Compare the request headers with the original headers\n",
    "original_headers = r.headers\n",
    "print(\"Original Headers:\")\n",
    "print(original_headers)\n",
    "print(\"\\nModified Headers:\")\n",
    "print(r.request.headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without custom header 400\n",
      "with custom headers 200\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Bypassing User-Agent Blocking\n",
    "\"\"\"\n",
    "# TODO: Send request to https://gamefaqs.gamespot.com/news using requests with and without custom headers\n",
    "# TODO: Compare the response, which one is blocked and which one is not\n",
    "r = requests.get('https://gamefaqs.gamespot.com/news')\n",
    "print(\"without custom header\",r.status_code)\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Accept': '*/*',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Connection': 'keep-alive'\n",
    "}\n",
    "\n",
    "rNew = requests.get('https://gamefaqs.gamespot.com/news', headers=headers)\n",
    "print(\"with custom headers\",rNew.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:92.0) Gecko/20100101 Firefox/92.0\n",
      "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\n",
      "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:50.0) Gecko/20100101 Firefox/50.0\n",
      "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36\n",
      "Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:92.0) Gecko/20100101 Firefox/92.0\n",
      "Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:92.0) Gecko/20100101 Firefox/92.0\n",
      "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\n",
      "Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:92.0) Gecko/20100101 Firefox/92.0\n",
      "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\n",
      "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Understanding User-Agent Rotation\n",
    "If all person you've met today using same shirts, what do you think?\n",
    "\"\"\"\n",
    "# List of common User-Agent strings\n",
    "user_agents = [\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:50.0) Gecko/20100101 Firefox/50.0',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:92.0) Gecko/20100101 Firefox/92.0'\n",
    "]\n",
    "\n",
    "# TODO: Send request to https://httpbin.org/get using random User-Agent from the list\n",
    "# TODO: Get the response and print the used User-Agent\n",
    "# TODO: Try to execute it again, is the User-Agent still the same?\n",
    "# TODO: Try to loop to send up to 10 request, using different User-Agent from the list and print each user agents used\n",
    "\n",
    "import random\n",
    "for i in range(10):\n",
    "    headers = {\n",
    "        'User-Agent': user_agents[random.randint(0, len(user_agents) - 1)]\n",
    "    }\n",
    "    r = requests.get('https://httpbin.org/get', headers=headers)\n",
    "    print(r.json()['headers']['User-Agent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mozilla/5.0 (iPhone; CPU iPhone OS 18_3_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.3 Mobile/15E148 Safari/604.1\n",
      "Mozilla/5.0 (iPhone; CPU iPhone OS 18_3_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.3 Mobile/15E148 Safari/604.1\n",
      "Mozilla/5.0 (X11; Linux x86_64; rv:125.0) Gecko/20100101 Firefox/125.0\n",
      "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.3 Safari/605.1.15\n",
      "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36\n",
      "Mozilla/5.0 (Linux; Android 10; K) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Mobile Safari/537.36\n",
      "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36\n",
      "Mozilla/5.0 (iPhone; CPU iPhone OS 18_3_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.3 Mobile/15E148 Safari/604.1\n",
      "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36\n",
      "Mozilla/5.0 (iPhone; CPU iPhone OS 18_3_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.3 Mobile/15E148 Safari/604.1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Using fake user-agent library\n",
    "\"\"\"\n",
    "# TODO: Install fake_useragent using pip\n",
    "# TODO: Create a UserAgent object\n",
    "# TODO: To get a random User-Agent, use ua.random\n",
    "# TODO: Send request to https://httpbin.org/get using random User-Agent from the fake_useragent\n",
    "# TODO: Get the response and print the used User-Agent\n",
    "# TODO: Try to execute it again, is the User-Agent still the same?\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "uAgent = UserAgent()\n",
    "\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    headers = {\n",
    "    'User-Agent': uAgent.random\n",
    "    }\n",
    "    r = requests.get('https://httpbin.org/get', headers=headers)\n",
    "    print(r.json()['headers']['User-Agent'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request succeeded with status code: 200\n",
      "Data saved to settlements.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Improve web scraping by using fake_useragent and logging\n",
    "\"\"\"\n",
    "# TODO: Visit https://www.cmegroup.com/markets/energy/crude-oil/light-sweet-crude.settlements.html\n",
    "# TODO: Try sending request to that site without custom header\n",
    "# TODO: If you failed, use random User-Agent using fake_useragent\n",
    "# TODO: Extract the data table and save it to a json file\n",
    "\n",
    "import logging\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "import pandas as pd\n",
    "from curl_cffi import requests\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "uAgent = UserAgent()\n",
    "timeout = 60  # Increased timeout to 60 seconds\n",
    "max_retries = 3  # Maximum number of retries\n",
    "url = 'https://www.cmegroup.com/CmeWS/mvc/Settlements/Futures/Settlements/425/FUT?strategy=DEFAULT&tradeDate=04/08/2025&pageSize=500&isProtected&_t=1744252567504'\n",
    "\n",
    "for attempt in range(max_retries):\n",
    "    try:\n",
    "        headers = { 'User-Agent': uAgent.random } # Random User-Agent from fake_useragent\n",
    "        r = requests.get(url, headers=headers, timeout=timeout, impersonate=\"chrome110\")  # Set timeout for the request\n",
    "        r.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "        break  # If the request is successful, break out of the loop\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "        if attempt < max_retries - 1:\n",
    "            time.sleep(10)  # Wait for 10 seconds before retrying\n",
    "        else:\n",
    "            logging.error(\"Max retries reached. Request failed.\")\n",
    "            exit()  # Exit the script if all retries fail\n",
    "\n",
    "if r.status_code == 200:\n",
    "    print(\"Request succeeded with status code:\", r.status_code)\n",
    "    data = r.json()\n",
    "    # Extract the data table from the response\n",
    "    df = pd.DataFrame(data['settlements'])\n",
    "    # Save the data to a JSON file\n",
    "    df.to_json('settlements.json', orient='records', lines=True)\n",
    "    print(\"Data saved to settlements.json\")\n",
    "\n",
    "    \n",
    "  \n",
    "else:\n",
    "    print(\"Request failed with status code:\", r.status_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Proxy Rotation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A proxy acts as an intermediary server between your scraping script (client) and the target website (server). When you send a request through a proxy, the request is routed through the proxy server, which then forwards the request to the destination website. The website sees the request coming from the proxy’s IP address instead of your actual IP address. This makes proxies particularly useful in web scraping, as they help with anonymity, bypassing rate limits, and preventing IP bans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending request 1. Status code: 403\n",
      "Sending request 2. Status code: 403\n",
      "Sending request 3. Status code: 403\n",
      "Sending request 4. Status code: 403\n",
      "Sending request 5. Status code: 403\n",
      "Sending request 6. Status code: 403\n",
      "Sending request 7. Status code: 403\n",
      "Sending request 8. Status code: 403\n",
      "Sending request 9. Status code: 403\n",
      "Sending request 10. Status code: 403\n",
      "Sending request 11. Status code: 403\n",
      "Sending request 12. Status code: 403\n",
      "Sending request 13. Status code: 403\n",
      "Sending request 14. Status code: 403\n",
      "Sending request 15. Status code: 403\n",
      "Sending request 16. Status code: 403\n",
      "Sending request 17. Status code: 403\n",
      "Sending request 18. Status code: 403\n",
      "Sending request 19. Status code: 403\n",
      "Sending request 20. Status code: 403\n",
      "Sending request 21. Status code: 403\n",
      "Sending request 22. Status code: 403\n",
      "Sending request 23. Status code: 403\n",
      "Sending request 24. Status code: 403\n",
      "Sending request 25. Status code: 403\n",
      "Sending request 26. Status code: 403\n",
      "Sending request 27. Status code: 403\n",
      "Sending request 28. Status code: 403\n",
      "Sending request 29. Status code: 403\n",
      "Sending request 30. Status code: 403\n",
      "Sending request 31. Status code: 403\n",
      "Sending request 32. Status code: 403\n",
      "Sending request 33. Status code: 403\n",
      "Sending request 34. Status code: 403\n",
      "Sending request 35. Status code: 403\n",
      "Sending request 36. Status code: 403\n",
      "Sending request 37. Status code: 403\n",
      "Sending request 38. Status code: 403\n",
      "Sending request 39. Status code: 403\n",
      "Sending request 40. Status code: 403\n",
      "Sending request 41. Status code: 403\n",
      "Sending request 42. Status code: 403\n",
      "Sending request 43. Status code: 403\n",
      "Sending request 44. Status code: 403\n",
      "Sending request 45. Status code: 403\n",
      "Sending request 46. Status code: 403\n",
      "Sending request 47. Status code: 403\n",
      "Sending request 48. Status code: 403\n",
      "Sending request 49. Status code: 403\n",
      "Sending request 50. Status code: 403\n",
      "Sending request 51. Status code: 403\n",
      "Sending request 52. Status code: 403\n",
      "Sending request 53. Status code: 403\n",
      "Sending request 54. Status code: 403\n",
      "Sending request 55. Status code: 403\n",
      "Sending request 56. Status code: 403\n",
      "Sending request 57. Status code: 403\n",
      "Sending request 58. Status code: 403\n",
      "Sending request 59. Status code: 403\n",
      "Sending request 60. Status code: 403\n",
      "Sending request 61. Status code: 403\n",
      "Sending request 62. Status code: 403\n",
      "Sending request 63. Status code: 403\n",
      "Sending request 64. Status code: 403\n",
      "Sending request 65. Status code: 403\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Understanding rate limits\n",
    "\"\"\"\n",
    "# TODO: Execute this cell\n",
    "\n",
    "url = \"https://api.github.com/users/octocat\"\n",
    "\n",
    "for i in range(1, 66):\n",
    "    response = requests.get(url)\n",
    "    print(f\"Sending request {i}. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proxy 51.44.176.151:20202 works! Response: {\n",
      "  \"origin\": \"185.199.228.220\"\n",
      "}\n",
      "\n",
      "Proxy 3.104.88.178:80 works! Response: {\n",
      "  \"origin\": \"86.38.234.176\"\n",
      "}\n",
      "\n",
      "Proxy 43.159.152.105:13001 works! Response: {\n",
      "  \"origin\": \"173.211.0.148\"\n",
      "}\n",
      "\n",
      "Proxy 170.106.135.2:13001 works! Response: {\n",
      "  \"origin\": \"86.38.234.176\"\n",
      "}\n",
      "\n",
      "Proxy 32.223.6.94:80 works! Response: {\n",
      "  \"origin\": \"86.38.234.176\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Understanding Proxy\n",
    "\"\"\"\n",
    "import requests\n",
    "\n",
    "# Open the proxies.txt file\n",
    "with open('proxies.txt', 'r') as file:\n",
    "    proxy_list = file.readlines()  # Read all lines into a list\n",
    "\n",
    "# Iterate over proxies\n",
    "for proxy in proxy_list:\n",
    "    proxy = proxy.strip()  # Remove leading/trailing whitespace\n",
    "    \n",
    "    # If authentication is needed\n",
    "    if \"@\" in proxy:\n",
    "        proxies = {\n",
    "            \"http\": f\"http://{proxy}\",\n",
    "            \"https\": f\"https://{proxy}\"\n",
    "        }\n",
    "    else:\n",
    "        # If only IP:Port\n",
    "        proxies = {\n",
    "            \"http\": f\"http://{proxy}\",\n",
    "            \"https\": f\"https://{proxy}\"\n",
    "        }\n",
    "    \n",
    "\n",
    "    #USE .ENV FILE FOR SENSITIVE DATA\n",
    "    import os\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    HTTP = os.getenv(\"HTTP\")\n",
    "    HTTPS = os.getenv(\"HTTPS\")\n",
    "\n",
    "    # Make a request using webshare.io proxy\n",
    "    webshare_Proxy = {\n",
    "      \"http\":HTTP,\n",
    "      \"https\": HTTPS\n",
    "    } \n",
    "    try:\n",
    "        response = requests.get(\"https://httpbin.org/ip\", proxies=webshare_Proxy, timeout=30)\n",
    "        print(f\"Proxy {proxy} works! Response: {response.text}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Proxy {proxy} failed. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request succeeded with status code: 200\n",
      "Data saved to settlements.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Improve web scraping by using fake_useragent and logging\n",
    "\"\"\"\n",
    "# TODO: Visit https://www.cmegroup.com/markets/energy/crude-oil/light-sweet-crude.settlements.html\n",
    "# TODO: Try sending request to that site without custom header\n",
    "# TODO: If you failed, use random User-Agent using fake_useragent\n",
    "# TODO: Extract the data table and save it to a json file\n",
    "\n",
    "import logging\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "import pandas as pd\n",
    "from curl_cffi import requests\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "uAgent = UserAgent()\n",
    "timeout = 60  # Increased timeout to 60 seconds\n",
    "max_retries = 3  # Maximum number of retries\n",
    "url = 'https://www.cmegroup.com/CmeWS/mvc/Settlements/Futures/Settlements/425/FUT?strategy=DEFAULT&tradeDate=04/08/2025&pageSize=500&isProtected&_t=1744252567504'\n",
    "\n",
    "for attempt in range(max_retries):\n",
    "    try:\n",
    "        headers = { 'User-Agent': uAgent.random } # Random User-Agent from fake_useragent\n",
    "        r = requests.get(url, headers=headers, timeout=timeout, impersonate=\"chrome110\")  # Set timeout for the request\n",
    "        r.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "        break  # If the request is successful, break out of the loop\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "        if attempt < max_retries - 1:\n",
    "            time.sleep(10)  # Wait for 10 seconds before retrying\n",
    "        else:\n",
    "            logging.error(\"Max retries reached. Request failed.\")\n",
    "            exit()  # Exit the script if all retries fail\n",
    "\n",
    "if r.status_code == 200:\n",
    "    print(\"Request succeeded with status code:\", r.status_code)\n",
    "    data = r.json()\n",
    "    # Extract the data table from the response\n",
    "    df = pd.DataFrame(data['settlements'])\n",
    "    # Save the data to a JSON file\n",
    "    df.to_json('settlements.json', orient='records', lines=True)\n",
    "    print(\"Data saved to settlements.json\")\n",
    "\n",
    "    \n",
    "  \n",
    "else:\n",
    "    print(\"Request failed with status code:\", r.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Objective: Finding free proxies\n",
    "\"\"\"\n",
    "# TODO: Do a google search for free proxies and share your thoughts\n",
    "# i am usually using webshare.io for free proxy. you will get 10 free proxies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "809\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Using free proxies\n",
    "\"\"\"\n",
    "\n",
    "proxy_url = \"https://api.proxyscrape.com/v4/free-proxy-list/get?request=display_proxies&proxy_format=protocolipport&format=text\"\n",
    "\n",
    "proxy_list = requests.get(proxy_url).text # Get the proxy list\n",
    "proxy_list = proxy_list.strip().split('\\r\\n') # Split the proxy list\n",
    "proxy_list = [proxy for proxy in proxy_list if 'http' in proxy] # Filter http only\n",
    "print(len(proxy_list))\n",
    "\n",
    "url = \"https://api.github.com/users/octocat\"\n",
    "\n",
    "# TODO: Trigger blocking by sending 60 or more request to the URL\n",
    "\n",
    "# TODO: Once we hit the rate limit, we need to use a proxy\n",
    "# TODO: A free proxy may not always work, use looping to find a working proxy (response.status_code == 200)\n",
    "# TODO: Once the request is successful, print the proxy used and exit the loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending request 1. Status code: 200\n",
      "Sending request 2. Status code: 200\n",
      "Sending request 3. Status code: 200\n",
      "Sending request 4. Status code: 200\n",
      "Sending request 5. Status code: 200\n",
      "Sending request 6. Status code: 200\n",
      "Sending request 7. Status code: 200\n",
      "Sending request 8. Status code: 200\n",
      "Sending request 9. Status code: 200\n",
      "Sending request 10. Status code: 200\n",
      "Sending request 11. Status code: 200\n",
      "Sending request 12. Status code: 200\n",
      "Sending request 13. Status code: 200\n",
      "Sending request 14. Status code: 200\n",
      "Sending request 15. Status code: 200\n",
      "Sending request 16. Status code: 200\n",
      "Sending request 17. Status code: 200\n",
      "Sending request 18. Status code: 200\n",
      "Sending request 19. Status code: 200\n",
      "Sending request 20. Status code: 200\n",
      "Sending request 21. Status code: 200\n",
      "Sending request 22. Status code: 200\n",
      "Sending request 23. Status code: 200\n",
      "Sending request 24. Status code: 200\n",
      "Sending request 25. Status code: 200\n",
      "Sending request 26. Status code: 200\n",
      "Sending request 27. Status code: 200\n",
      "Sending request 28. Status code: 200\n",
      "Sending request 29. Status code: 200\n",
      "Sending request 30. Status code: 200\n",
      "Sending request 31. Status code: 200\n",
      "Sending request 32. Status code: 200\n",
      "Sending request 33. Status code: 200\n",
      "Sending request 34. Status code: 200\n",
      "Sending request 35. Status code: 200\n",
      "Sending request 36. Status code: 200\n",
      "Sending request 37. Status code: 200\n",
      "Sending request 38. Status code: 200\n",
      "Sending request 39. Status code: 200\n",
      "Sending request 40. Status code: 200\n",
      "Sending request 41. Status code: 200\n",
      "Sending request 42. Status code: 200\n",
      "Sending request 43. Status code: 200\n",
      "Sending request 44. Status code: 200\n",
      "Sending request 45. Status code: 200\n",
      "Sending request 46. Status code: 200\n",
      "Sending request 47. Status code: 200\n",
      "Sending request 48. Status code: 200\n",
      "Sending request 49. Status code: 200\n",
      "Sending request 50. Status code: 200\n",
      "Sending request 51. Status code: 200\n",
      "Sending request 52. Status code: 200\n",
      "Sending request 53. Status code: 200\n",
      "Sending request 54. Status code: 200\n",
      "Sending request 55. Status code: 200\n",
      "Sending request 56. Status code: 200\n",
      "Sending request 57. Status code: 200\n",
      "Sending request 58. Status code: 200\n",
      "Sending request 59. Status code: 200\n",
      "Sending request 60. Status code: 200\n",
      "Sending request 61. Status code: 403\n",
      "Sending request 62. Status code: 403\n",
      "Sending request 63. Status code: 403\n",
      "Sending request 64. Status code: 403\n",
      "Sending request 65. Status code: 403\n"
     ]
    }
   ],
   "source": [
    "url = \"https://api.github.com/users/octocat\"\n",
    "\n",
    "# TODO: Trigger blocking by sending 60 or more request to the URL\n",
    "for i in range(1, 66):\n",
    "    response = requests.get(url)\n",
    "    print(f\"Sending request {i}. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending request 1. Status code: 200\n",
      "Proxy http://15.235.53.20:28003 works! Response: {\"login\":\"octocat\",\"id\":583231,\"node_id\":\"MDQ6VXNlcjU4MzIzMQ==\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/583231?v=4\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/octocat\",\"html_url\":\"https://github.com/octocat\",\"followers_url\":\"https://api.github.com/users/octocat/followers\",\"following_url\":\"https://api.github.com/users/octocat/following{/other_user}\",\"gists_url\":\"https://api.github.com/users/octocat/gists{/gist_id}\",\"starred_url\":\"https://api.github.com/users/octocat/starred{/owner}{/repo}\",\"subscriptions_url\":\"https://api.github.com/users/octocat/subscriptions\",\"organizations_url\":\"https://api.github.com/users/octocat/orgs\",\"repos_url\":\"https://api.github.com/users/octocat/repos\",\"events_url\":\"https://api.github.com/users/octocat/events{/privacy}\",\"received_events_url\":\"https://api.github.com/users/octocat/received_events\",\"type\":\"User\",\"user_view_type\":\"public\",\"site_admin\":false,\"name\":\"The Octocat\",\"company\":\"@github\",\"blog\":\"https://github.blog\",\"location\":\"San Francisco\",\"email\":null,\"hireable\":null,\"bio\":null,\"twitter_username\":null,\"public_repos\":8,\"public_gists\":8,\"followers\":17567,\"following\":9,\"created_at\":\"2011-01-25T18:44:36Z\",\"updated_at\":\"2025-03-22T11:26:21Z\"}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Once we hit the rate limit, we need to use a proxy\n",
    "# TODO: A free proxy may not always work, use looping to find a working proxy (response.status_code == 200)\n",
    "# TODO: Once the request is successful, print the proxy used and exit the loop\n",
    "url = \"https://api.github.com/users/octocat\"\n",
    "for i in range(1, 66):\n",
    "    response = requests.get(url, proxies=webshare_Proxy)\n",
    "    print(f\"Sending request {i}. Status code: {response.status_code}\")\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Proxy {proxy} works! Response: {response.text}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reflection**\n",
    "What user-agent that typically get blocked? Can you mention it?\n",
    "\n",
    "1. Web Scraping Bots\n",
    "- Python-urllib/3.9\n",
    "- Scrapy/2.5\n",
    "- Java/1.8.0_181\n",
    "- curl/7.64.1\n",
    "- wget/1.20.3\n",
    "\n",
    "2. Malicious or Suspicious Bots\n",
    "- AhrefsBot\n",
    "- MJ12bot\n",
    "- SemrushBot\n",
    "- DotBot\n",
    "- BLEXBot\n",
    "\n",
    "3. Outdated Browsers\n",
    "- Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1)\n",
    "- Mozilla/5.0 (Windows NT 5.1; rv:1.9.2.3) Gecko/20100401 Firefox/3.6.3\n",
    "\n",
    "4. Generic or Empty User-Agents\n",
    "- Mozilla/5.0 (compatible; GenericBot/1.0)\n",
    "- - (empty user-agent string)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exploration**\n",
    "There are a lot of proxy providers out there. Do a research on at least 3 of them and compare it.\n",
    "\n",
    "https://medium.com/@rjrizani_66086/analysis-of-recommended-free-proxy-providers-for-web-scraping-776ff914ef6c    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
